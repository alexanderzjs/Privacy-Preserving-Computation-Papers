# 2022 Security Papers and Posters
## Winter
1. Poison Forensics: Traceback of Data Poisoning Attacks in Neural Networks. Shawn Shan, Arjun Nitin Bhagoji, Haitao Zheng, and Ben Y. Zhao, University of Chicago
2. Practical Privacy-Preserving Authentication for SSH. Lawrence Roy, Stanislav Lyakhov, Yeongjin Jang, and Mike Rosulek, Oregon State University
3. Estimating Incidental Collection in Foreign Intelligence Surveillance: Large-Scale Multiparty Private Set Intersection with Union and Sum. Anunay Kulshrestha and Jonathan Mayer, Princeton University
4. Teacher Model Fingerprinting Attacks Against Transfer Learning. Yufei Chen, Xi'an Jiaotong University & City University of Hong Kong; Chao Shen, Xi'an Jiaotong University; Cong Wang, City University of Hong Kong; Yang Zhang, CISPA Helmholtz Center for Information Security
5. Piranha: A GPU Platform for Secure Computation. Jean-Luc Watson, Sameer Wagh, and Raluca Ada Popa, University of California, Berkeley
6. PoisonedEncoder: Poisoning the Unlabeled Pre-training Data in Contrastive Learning. Hongbin Liu, Jinyuan Jia, and Neil Zhenqiang Gong, Duke University
7. Pool Inference Attacks on Local Differential Privacy: Quantifying the Privacy Guarantees of Apple's Count Mean Sketch in Practice. Andrea Gadotti, Imperial College London; Florimond Houssiau, Alan Turing Institute; Meenatchi Sundaram Muthu Selva Annamalai and Yves-Alexandre de Montjoye, Imperial College London
8. Batched Differentially Private Information Retrieval. Kinan Dak Albab, Brown University; Rawane Issa and Mayank Varia, Boston University; Kalman Graffi, Honda Research Institute Europe
9. GPU-accelerated PIR with Client-Independent Preprocessing for Large-Scale Applications. Daniel Günther and Maurice Heymann, Technical University of Darmstadt; Benny Pinkas, Bar-Ilan University; Thomas Schneider, Technical University of Darmstadt

## Fall
1. Cheetah: Lean and Fast Secure Two-Party Deep Neural Network Inference. Zhicong Huang, Wen-jie Lu, Cheng Hong, and Jiansheng Ding, Alibaba Group
2. ppSAT: Towards Two-Party Private SAT Solving. Ning Luo, Samuel Judson, Timos Antonopoulos, and Ruzica Piskac, Yale University; Xiao Wang, Northwestern University
3. Poisoning Attacks to Local Differential Privacy Protocols for Key-Value Data. Yongji Wu, Xiaoyu Cao, Jinyuan Jia, and Neil Zhenqiang Gong, Duke University
4. Communication-Efficient Triangle Counting under Local Differential Privacy. Jacob Imola, UC San Diego; Takao Murakami, AIST; Kamalika Chaudhuri, UC San Diego
5. Constant-weight PIR: Single-round Keyword PIR via Constant-weight Equality Operators. Rasoul Akhavan Mahdavi and Florian Kerschbaum, University of Waterloo
6. Seeing is Living? Rethinking the Security of Facial Liveness Verification in the Deepfake Era. Changjiang Li, Pennsylvania State University and Zhejiang University; Li Wang, Shandong University; Shouling Ji and Xuhong Zhang, Zhejiang University; Zhaohan Xi, Pennsylvania State University; Shanqing Guo, Shandong University; Ting Wang, Pennsylvania State University
7. Mitigating Membership Inference Attacks by Self-Distillation Through a Novel Ensemble Architecture. Xinyu Tang, Saeed Mahloujifar, and Liwei Song, Princeton University; Virat Shejwalkar, Milad Nasr, and Amir Houmansadr, University of Massachusetts Amherst; Prateek Mittal, Princeton University
8. Membership Inference Attacks and Defenses in Neural Network Pruning. Xiaoyong Yuan and Lan Zhang, Michigan Technological Unviersity
9. Efficient Differentially Private Secure Aggregation for Federated Learning via Hardness of Learning with Errors. Timothy Stevens, Christian Skalka, and Christelle Vincent, University of Vermont; John Ring, MassMutual; Samuel Clark, Raytheon; Joseph Near, University of Vermont
10. Shuffle-based Private Set Union: Faster and More Secure. Yanxue Jia and Shi-Feng Sun, Shanghai Jiao Tong University; Hong-Sheng Zhou, Virginia Commonwealth University; Jiajun Du and Dawu Gu, Shanghai Jiao Tong University
11. Are Your Sensitive Attributes Private? Novel Model Inversion Attribute Inference Attacks on Classification Models. Shagufta Mehnaz; The Pennsylvania State University; Sayanton V. Dibbo and Ehsanul Kabir, Dartmouth College; Ninghui Li and Elisa Bertino, Purdue University
12. FLAME: Taming Backdoors in Federated Learning. Thien Duc Nguyen and Phillip Rieger, Technical University of Darmstadt; Huili Chen, University of California San Diego; Hossein Yalame, Helen Möllering, and Hossein Fereidooni, Technical University of Darmstadt; Samuel Marchal, Aalto University and F-Secure; Markus Miettinen, Technical University of Darmstadt; Azalia Mirhoseini, Google; Shaza Zeitouni, Technical University of Darmstadt; Farinaz Koushanfar, University of California San Diego; Ahmad-Reza Sadeghi and Thomas Schneider, Technical University of Darmstadt

## Summer
1. Increasing Adversarial Uncertainty to Scale Private Similarity Testing. Yiqing Hua and Armin Namavari, Cornell Tech and Cornell University; Kaishuo Cheng, Cornell University; Mor Naaman and Thomas Ristenpart, Cornell Tech and Cornell University
2. ML-Doctor: Holistic Risk Assessment of Inference Attacks Against Machine Learning Models. Yugeng Liu, Rui Wen, Xinlei He, Ahmed Salem, Zhikun Zhang, and Michael Backes, CISPA Helmholtz Center for Information Security; Emiliano De Cristofaro, UCL and Alan Turing Institute; Mario Fritz and Yang Zhang, CISPA Helmholtz Center for Information Security
3. PrivGuard: Privacy Regulation Compliance Made Easier. Lun Wang, UC Berkeley; Usmann Khan, Georgia Tech; Joseph Near, University of Vermont; Qi Pang, Zhejiang University; Jithendaraa Subramanian, NIT Tiruchirappalli; Neel Somani, UC Berkeley; Peng Gao, Virginia Tech; Andrew Low and Dawn Song, UC Berkeley
4. Caring about Sharing: User Perceptions of Multiparty Data Sharing. Bailey Kacsmar, Kyle Tilbury, Miti Mazmudar, and Florian Kerschbaum, University of Waterloo
5. Inference Attacks Against Graph Neural Networks. Zhikun Zhang, Min Chen, and Michael Backes, CISPA Helmholtz Center for Information Security; Yun Shen, Norton Research Group; Yang Zhang, CISPA Helmholtz Center for Information Security
6. Incremental Offline/Online PIR. Yiping Ma and Ke Zhong, University of Pennsylvania; Tal Rabin, University of Pennsylvania and Algorand Foundation; Sebastian Angel, University of Pennsylvania and Microsoft Research
7. Secure Poisson Regression. Mahimna Kelkar, Cornell Tech; Phi Hung Le, Mariana Raykova, and Karn Seth, Google
8. Label Inference Attacks Against Vertical Federated Learning. Chong Fu, Zhejiang University; Xuhong Zhang and Shouling Ji, Binjiang Institute of Zhejiang University; Jinyin Chen, Zhejiang University of Technology; Jingzheng Wu, Institute of Software, Chinese Academy of Sciences; Shanqing Guo, Shandong University; Jun Zhou and Alex X. Liu, Ant Group; Ting Wang, Pennsylvania State University
9. SIMC: ML Inference Secure Against Malicious Clients at Semi-Honest Cost. Nishanth Chandran, Divya Gupta, and Sai Lakshmi Bhavana Obbattu, Microsoft Research; Akash Shah, UCLA

Poster 1. Camel: Cryptographic Audits for Collaborative Machine Learning. Hidde Lycklama, Nicolas Küchler, Emanuel Opel, Lukas Burkhalter, and Anwar Hithnawi, ETH Zurich

Poster 2. Identifying Harmful Media in End-to-End Encrypted Communication: Efficient Private Membership Computation. Anunay Kulshrestha and Jonathan Mayer, Princeton University

Poster 3. EIFFeL: Ensuring Integrity for Federated Learning. Amrita Roy Chowdhury, UW-Madison; Chuan Guo, Meta AI; Somesh Jha, UW-Madison; Laurens van der Maaten, Meta AI

Poster 4. Privacy and Integrity Preserving Computations with CRISP. Sylvain Chatel, Apostolos Pyrgelis, Juan Ramon Troncoso Pastoriza, and Jean-Pierre Hubaux, EPFL

Poster 5. Blind Backdoors in Deep Learning Models. Eugene Bagdasaryan and Vitaly Shmatikov, Cornell Tech
